{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second tier CNN and feature extraction\n",
    "\n",
    "### This file has the results of the secod tier CNN and the extraction of CNN features. The steps performed are:\n",
    "\n",
    "1. This BSD is fed to a second-tier CNN and is trained for 150 epochs \n",
    "2. The CNN used has 4 convolutional layers having 32,64, 128 and 256 filters with filter size 3*3.  \n",
    "3. From this CNN, the 3rd dense layer is selected for feature selection. \n",
    "4. 64 features of importance are selected by the CNN which is stored. \n",
    "5. These features are a result of a fully connected layer with 64 units (features) with ReLu as the activation function. \n",
    "6. Binary cross entropy is the loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.initializers import Constant\n",
    "\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from keras.applications import MobileNetV2\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.applications import MobileNetV2\n",
    "import imageio\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The malignant and benign data is loaded to np arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "def Load_data_malignant():\n",
    "    path =\"final/malignant\"\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(1, 314):\n",
    "        img = imageio.imread(path +'/' + '1' + ' (' + str(i) + ')' + '.jpg')\n",
    "        lab = 1 \n",
    "        x_out.append(img)\n",
    "        y_out.append(lab)\n",
    "    return x_out, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_data_benign():\n",
    "    path =\"final/benign\"\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(1, 314):\n",
    "        img = imageio.imread(path +'/' + '1' + ' (' + str(i) + ')' + '.jpg')\n",
    "        lab = 0 \n",
    "        x_out.append(img)\n",
    "        y_out.append(lab)\n",
    "    return x_out, y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benign and malignant arrays are assigned to x and y arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0, y_0 = Load_data_benign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1, y_1 = Load_data_malignant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arrays are concatenated to form x and y arrays (features, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = np.array(x_0)\n",
    "y_0 = np.array(y_0)\n",
    "\n",
    "x_1 = np.array(x_1)\n",
    "y_1 = np.array(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "x=np.concatenate((x_0, x_1), axis=0)\n",
    "y=np.concatenate((y_0, y_1), axis=0)\n",
    "\n",
    "y = np_utils.to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is split as train and test with 70:30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_Test, y_train, y_Test = train_test_split(x, y, test_size=0.3, random_state=5,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438, 224, 224, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN model is defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 224, 224, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 112, 112, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 200704)            0         \n",
      "                                                                 \n",
      " feature_dense1 (Dense)      (None, 256)               51380480  \n",
      "                                                                 \n",
      " feature_dense2 (Dense)      (None, 128)               32896     \n",
      "                                                                 \n",
      " feature_dense3 (Dense)      (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,812,194\n",
      "Trainable params: 51,812,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=[224,224,3]),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPool2D(2),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPool2D(2),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPool2D(2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu',name ='feature_dense1'),\n",
    "    keras.layers.Dense(128, activation='relu',name ='feature_dense2'),\n",
    "    keras.layers.Dense(64, activation='relu',name ='feature_dense3'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='sigmoid')\n",
    "   ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer is chosen as Adamax, binary cross entropy is the loss function, with epochs as 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adamax()\n",
    "model.compile(optimizer=optimizer, loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is fit to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "11/11 [==============================] - 49s 4s/step - loss: 78.1600 - accuracy: 0.4840 - val_loss: 2.9758 - val_accuracy: 0.5000\n",
      "Epoch 2/150\n",
      "11/11 [==============================] - 48s 4s/step - loss: 1.6092 - accuracy: 0.5502 - val_loss: 0.6193 - val_accuracy: 0.5957\n",
      "Epoch 3/150\n",
      "11/11 [==============================] - 54s 5s/step - loss: 0.5985 - accuracy: 0.6735 - val_loss: 0.6021 - val_accuracy: 0.6702\n",
      "Epoch 4/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 0.5155 - accuracy: 0.7352 - val_loss: 0.4967 - val_accuracy: 0.7447\n",
      "Epoch 5/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 0.4460 - accuracy: 0.7785 - val_loss: 0.5173 - val_accuracy: 0.7287\n",
      "Epoch 6/150\n",
      "11/11 [==============================] - 49s 5s/step - loss: 0.4554 - accuracy: 0.7580 - val_loss: 0.5353 - val_accuracy: 0.7181\n",
      "Epoch 7/150\n",
      "11/11 [==============================] - 49s 5s/step - loss: 0.4215 - accuracy: 0.8196 - val_loss: 0.5111 - val_accuracy: 0.7394\n",
      "Epoch 8/150\n",
      "11/11 [==============================] - 49s 5s/step - loss: 0.3591 - accuracy: 0.8447 - val_loss: 0.5166 - val_accuracy: 0.7340\n",
      "Epoch 9/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 0.3372 - accuracy: 0.8402 - val_loss: 0.5071 - val_accuracy: 0.7606\n",
      "Epoch 10/150\n",
      "11/11 [==============================] - 53s 5s/step - loss: 0.2739 - accuracy: 0.8836 - val_loss: 0.6886 - val_accuracy: 0.7234\n",
      "Epoch 11/150\n",
      "11/11 [==============================] - 59s 5s/step - loss: 0.2449 - accuracy: 0.8927 - val_loss: 0.6012 - val_accuracy: 0.7074\n",
      "Epoch 12/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 0.2024 - accuracy: 0.9201 - val_loss: 0.6529 - val_accuracy: 0.7394\n",
      "Epoch 13/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 0.1675 - accuracy: 0.9361 - val_loss: 0.7299 - val_accuracy: 0.7340\n",
      "Epoch 14/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 0.1267 - accuracy: 0.9612 - val_loss: 0.8746 - val_accuracy: 0.6862\n",
      "Epoch 15/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 0.1267 - accuracy: 0.9429 - val_loss: 1.1013 - val_accuracy: 0.7021\n",
      "Epoch 16/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 0.1095 - accuracy: 0.9612 - val_loss: 0.8975 - val_accuracy: 0.7181\n",
      "Epoch 17/150\n",
      "11/11 [==============================] - 52s 5s/step - loss: 0.0681 - accuracy: 0.9840 - val_loss: 1.0712 - val_accuracy: 0.6915\n",
      "Epoch 18/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 0.0689 - accuracy: 0.9795 - val_loss: 0.8898 - val_accuracy: 0.7340\n",
      "Epoch 19/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 0.0346 - accuracy: 0.9932 - val_loss: 0.9973 - val_accuracy: 0.7500\n",
      "Epoch 20/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 0.0240 - accuracy: 0.9954 - val_loss: 1.1717 - val_accuracy: 0.7447\n",
      "Epoch 21/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.0864 - val_accuracy: 0.7394\n",
      "Epoch 22/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 0.0206 - accuracy: 0.9977 - val_loss: 1.3778 - val_accuracy: 0.6968\n",
      "Epoch 23/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.2444 - val_accuracy: 0.7021\n",
      "Epoch 24/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.2670 - val_accuracy: 0.7447\n",
      "Epoch 25/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.3750 - val_accuracy: 0.7340\n",
      "Epoch 26/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.3799 - val_accuracy: 0.7340\n",
      "Epoch 27/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.4295 - val_accuracy: 0.7500\n",
      "Epoch 28/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.4648 - val_accuracy: 0.7340\n",
      "Epoch 29/150\n",
      "11/11 [==============================] - 63s 6s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4738 - val_accuracy: 0.7447\n",
      "Epoch 30/150\n",
      "11/11 [==============================] - 53s 5s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4261 - val_accuracy: 0.7713\n",
      "Epoch 31/150\n",
      "11/11 [==============================] - 53s 5s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5314 - val_accuracy: 0.7606\n",
      "Epoch 32/150\n",
      "11/11 [==============================] - 52s 5s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.5333 - val_accuracy: 0.7553\n",
      "Epoch 33/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.5075 - val_accuracy: 0.7766\n",
      "Epoch 34/150\n",
      "11/11 [==============================] - 52s 5s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6591 - val_accuracy: 0.7181\n",
      "Epoch 35/150\n",
      "11/11 [==============================] - 52s 5s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5308 - val_accuracy: 0.7606\n",
      "Epoch 36/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 9.9607e-04 - accuracy: 1.0000 - val_loss: 1.6522 - val_accuracy: 0.7660\n",
      "Epoch 37/150\n",
      "11/11 [==============================] - 52s 5s/step - loss: 9.0687e-04 - accuracy: 1.0000 - val_loss: 1.6315 - val_accuracy: 0.7660\n",
      "Epoch 38/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 7.7018e-04 - accuracy: 1.0000 - val_loss: 1.6302 - val_accuracy: 0.7606\n",
      "Epoch 39/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 6.6320e-04 - accuracy: 1.0000 - val_loss: 1.6389 - val_accuracy: 0.7500\n",
      "Epoch 40/150\n",
      "11/11 [==============================] - 52s 5s/step - loss: 6.0626e-04 - accuracy: 1.0000 - val_loss: 1.7125 - val_accuracy: 0.7766\n",
      "Epoch 41/150\n",
      "11/11 [==============================] - 53s 5s/step - loss: 5.3325e-04 - accuracy: 1.0000 - val_loss: 1.7693 - val_accuracy: 0.7500\n",
      "Epoch 42/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 4.8725e-04 - accuracy: 1.0000 - val_loss: 1.7935 - val_accuracy: 0.7606\n",
      "Epoch 43/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 4.3828e-04 - accuracy: 1.0000 - val_loss: 1.8082 - val_accuracy: 0.7606\n",
      "Epoch 44/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 3.8950e-04 - accuracy: 1.0000 - val_loss: 1.8519 - val_accuracy: 0.7606\n",
      "Epoch 45/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 3.5418e-04 - accuracy: 1.0000 - val_loss: 1.8549 - val_accuracy: 0.7553\n",
      "Epoch 46/150\n",
      "11/11 [==============================] - 59s 5s/step - loss: 3.2816e-04 - accuracy: 1.0000 - val_loss: 1.9586 - val_accuracy: 0.7447\n",
      "Epoch 47/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 2.8772e-04 - accuracy: 1.0000 - val_loss: 1.9035 - val_accuracy: 0.7500\n",
      "Epoch 48/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 2.6932e-04 - accuracy: 1.0000 - val_loss: 1.9532 - val_accuracy: 0.7553\n",
      "Epoch 49/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 2.3563e-04 - accuracy: 1.0000 - val_loss: 1.9736 - val_accuracy: 0.7394\n",
      "Epoch 50/150\n",
      "11/11 [==============================] - 52s 5s/step - loss: 2.0688e-04 - accuracy: 1.0000 - val_loss: 1.9922 - val_accuracy: 0.7340\n",
      "Epoch 51/150\n",
      "11/11 [==============================] - 61s 6s/step - loss: 1.9002e-04 - accuracy: 1.0000 - val_loss: 2.0524 - val_accuracy: 0.7500\n",
      "Epoch 52/150\n",
      "11/11 [==============================] - 48s 4s/step - loss: 1.7280e-04 - accuracy: 1.0000 - val_loss: 2.0299 - val_accuracy: 0.7287\n",
      "Epoch 53/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 1.5504e-04 - accuracy: 1.0000 - val_loss: 2.1423 - val_accuracy: 0.7340\n",
      "Epoch 54/150\n",
      "11/11 [==============================] - 49s 4s/step - loss: 1.3621e-04 - accuracy: 1.0000 - val_loss: 2.0889 - val_accuracy: 0.7340\n",
      "Epoch 55/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 1.2268e-04 - accuracy: 1.0000 - val_loss: 2.1546 - val_accuracy: 0.7394\n",
      "Epoch 56/150\n",
      "11/11 [==============================] - 46s 4s/step - loss: 1.1144e-04 - accuracy: 1.0000 - val_loss: 2.1406 - val_accuracy: 0.7340\n",
      "Epoch 57/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 1.0437e-04 - accuracy: 1.0000 - val_loss: 2.2874 - val_accuracy: 0.7394\n",
      "Epoch 58/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 1.0189e-04 - accuracy: 1.0000 - val_loss: 2.1572 - val_accuracy: 0.7287\n",
      "Epoch 59/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 8.7304e-05 - accuracy: 1.0000 - val_loss: 2.3047 - val_accuracy: 0.7287\n",
      "Epoch 60/150\n",
      "11/11 [==============================] - 46s 4s/step - loss: 7.7027e-05 - accuracy: 1.0000 - val_loss: 2.2692 - val_accuracy: 0.7394\n",
      "Epoch 61/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 6.7204e-05 - accuracy: 1.0000 - val_loss: 2.3310 - val_accuracy: 0.7447\n",
      "Epoch 62/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 6.4106e-05 - accuracy: 1.0000 - val_loss: 2.3039 - val_accuracy: 0.7340\n",
      "Epoch 63/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 5.5409e-05 - accuracy: 1.0000 - val_loss: 2.4290 - val_accuracy: 0.7447\n",
      "Epoch 64/150\n",
      "11/11 [==============================] - 49s 5s/step - loss: 4.9328e-05 - accuracy: 1.0000 - val_loss: 2.3298 - val_accuracy: 0.7394\n",
      "Epoch 65/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 4.5203e-05 - accuracy: 1.0000 - val_loss: 2.3896 - val_accuracy: 0.7447\n",
      "Epoch 66/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 3.9299e-05 - accuracy: 1.0000 - val_loss: 2.4257 - val_accuracy: 0.7447\n",
      "Epoch 67/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 3.8407e-05 - accuracy: 1.0000 - val_loss: 2.3981 - val_accuracy: 0.7394\n",
      "Epoch 68/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 3.4037e-05 - accuracy: 1.0000 - val_loss: 2.4556 - val_accuracy: 0.7394\n",
      "Epoch 69/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 3.0148e-05 - accuracy: 1.0000 - val_loss: 2.4683 - val_accuracy: 0.7394\n",
      "Epoch 70/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 2.8673e-05 - accuracy: 1.0000 - val_loss: 2.4911 - val_accuracy: 0.7447\n",
      "Epoch 71/150\n",
      "11/11 [==============================] - 49s 5s/step - loss: 2.4313e-05 - accuracy: 1.0000 - val_loss: 2.4748 - val_accuracy: 0.7500\n",
      "Epoch 72/150\n",
      "11/11 [==============================] - 52s 5s/step - loss: 2.2530e-05 - accuracy: 1.0000 - val_loss: 2.5783 - val_accuracy: 0.7287\n",
      "Epoch 73/150\n",
      "11/11 [==============================] - 49s 5s/step - loss: 2.1179e-05 - accuracy: 1.0000 - val_loss: 2.4885 - val_accuracy: 0.7447\n",
      "Epoch 74/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 1.9501e-05 - accuracy: 1.0000 - val_loss: 2.6204 - val_accuracy: 0.7287\n",
      "Epoch 75/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 2.1385e-05 - accuracy: 1.0000 - val_loss: 2.7740 - val_accuracy: 0.7447\n",
      "Epoch 76/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 2.5534e-05 - accuracy: 1.0000 - val_loss: 2.4347 - val_accuracy: 0.7287\n",
      "Epoch 77/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 1.8642e-05 - accuracy: 1.0000 - val_loss: 2.5606 - val_accuracy: 0.7340\n",
      "Epoch 78/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 1.6376e-05 - accuracy: 1.0000 - val_loss: 2.6262 - val_accuracy: 0.7234\n",
      "Epoch 79/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 1.4158e-05 - accuracy: 1.0000 - val_loss: 2.6823 - val_accuracy: 0.7340\n",
      "Epoch 80/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 1.3291e-05 - accuracy: 1.0000 - val_loss: 2.6408 - val_accuracy: 0.7340\n",
      "Epoch 81/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 1.2084e-05 - accuracy: 1.0000 - val_loss: 2.6657 - val_accuracy: 0.7340\n",
      "Epoch 82/150\n",
      "11/11 [==============================] - 48s 4s/step - loss: 1.0867e-05 - accuracy: 1.0000 - val_loss: 2.6899 - val_accuracy: 0.7287\n",
      "Epoch 83/150\n",
      "11/11 [==============================] - 55s 5s/step - loss: 1.0258e-05 - accuracy: 1.0000 - val_loss: 2.7171 - val_accuracy: 0.7287\n",
      "Epoch 84/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 9.3628e-06 - accuracy: 1.0000 - val_loss: 2.7125 - val_accuracy: 0.7340\n",
      "Epoch 85/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 8.9728e-06 - accuracy: 1.0000 - val_loss: 2.7432 - val_accuracy: 0.7340\n",
      "Epoch 86/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 8.3120e-06 - accuracy: 1.0000 - val_loss: 2.7336 - val_accuracy: 0.7287\n",
      "Epoch 87/150\n",
      "11/11 [==============================] - 48s 4s/step - loss: 7.9025e-06 - accuracy: 1.0000 - val_loss: 2.7482 - val_accuracy: 0.7287\n",
      "Epoch 88/150\n",
      "11/11 [==============================] - 48s 4s/step - loss: 7.5494e-06 - accuracy: 1.0000 - val_loss: 2.7860 - val_accuracy: 0.7287\n",
      "Epoch 89/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 7.2157e-06 - accuracy: 1.0000 - val_loss: 2.7663 - val_accuracy: 0.7287\n",
      "Epoch 90/150\n",
      "11/11 [==============================] - 48s 4s/step - loss: 6.8812e-06 - accuracy: 1.0000 - val_loss: 2.7817 - val_accuracy: 0.7340\n",
      "Epoch 91/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 6.4638e-06 - accuracy: 1.0000 - val_loss: 2.7909 - val_accuracy: 0.7287\n",
      "Epoch 92/150\n",
      "11/11 [==============================] - 48s 4s/step - loss: 6.2050e-06 - accuracy: 1.0000 - val_loss: 2.8028 - val_accuracy: 0.7234\n",
      "Epoch 93/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 5.8411e-06 - accuracy: 1.0000 - val_loss: 2.8141 - val_accuracy: 0.7340\n",
      "Epoch 94/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 5.5836e-06 - accuracy: 1.0000 - val_loss: 2.8266 - val_accuracy: 0.7340\n",
      "Epoch 95/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 5.3611e-06 - accuracy: 1.0000 - val_loss: 2.8260 - val_accuracy: 0.7287\n",
      "Epoch 96/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 5.0410e-06 - accuracy: 1.0000 - val_loss: 2.8451 - val_accuracy: 0.7234\n",
      "Epoch 97/150\n",
      "11/11 [==============================] - 48s 4s/step - loss: 4.8499e-06 - accuracy: 1.0000 - val_loss: 2.8611 - val_accuracy: 0.7340\n",
      "Epoch 98/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 4.7333e-06 - accuracy: 1.0000 - val_loss: 2.8420 - val_accuracy: 0.7340\n",
      "Epoch 99/150\n",
      "11/11 [==============================] - 48s 4s/step - loss: 4.6928e-06 - accuracy: 1.0000 - val_loss: 2.8897 - val_accuracy: 0.7287\n",
      "Epoch 100/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 4.4147e-06 - accuracy: 1.0000 - val_loss: 2.8576 - val_accuracy: 0.7287\n",
      "Epoch 101/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 4.0942e-06 - accuracy: 1.0000 - val_loss: 2.8969 - val_accuracy: 0.7340\n",
      "Epoch 102/150\n",
      "11/11 [==============================] - 54s 5s/step - loss: 4.0699e-06 - accuracy: 1.0000 - val_loss: 2.8722 - val_accuracy: 0.7287\n",
      "Epoch 103/150\n",
      "11/11 [==============================] - 48s 4s/step - loss: 3.8492e-06 - accuracy: 1.0000 - val_loss: 2.9032 - val_accuracy: 0.7340\n",
      "Epoch 104/150\n",
      "11/11 [==============================] - 48s 4s/step - loss: 3.6164e-06 - accuracy: 1.0000 - val_loss: 2.9097 - val_accuracy: 0.7340\n",
      "Epoch 105/150\n",
      "11/11 [==============================] - 48s 4s/step - loss: 3.4948e-06 - accuracy: 1.0000 - val_loss: 2.9262 - val_accuracy: 0.7287\n",
      "Epoch 106/150\n",
      "11/11 [==============================] - 49s 4s/step - loss: 3.4671e-06 - accuracy: 1.0000 - val_loss: 2.9247 - val_accuracy: 0.7340\n",
      "Epoch 107/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 3.3293e-06 - accuracy: 1.0000 - val_loss: 2.9249 - val_accuracy: 0.7340\n",
      "Epoch 108/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 3.2627e-06 - accuracy: 1.0000 - val_loss: 2.9429 - val_accuracy: 0.7340\n",
      "Epoch 109/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 3.0919e-06 - accuracy: 1.0000 - val_loss: 2.9555 - val_accuracy: 0.7287\n",
      "Epoch 110/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 2.9851e-06 - accuracy: 1.0000 - val_loss: 2.9664 - val_accuracy: 0.7340\n",
      "Epoch 111/150\n",
      "11/11 [==============================] - 52s 5s/step - loss: 2.8622e-06 - accuracy: 1.0000 - val_loss: 2.9639 - val_accuracy: 0.7340\n",
      "Epoch 112/150\n",
      "11/11 [==============================] - 56s 5s/step - loss: 2.7301e-06 - accuracy: 1.0000 - val_loss: 2.9831 - val_accuracy: 0.7287\n",
      "Epoch 113/150\n",
      "11/11 [==============================] - 58s 5s/step - loss: 2.6307e-06 - accuracy: 1.0000 - val_loss: 2.9711 - val_accuracy: 0.7394\n",
      "Epoch 114/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 48s 4s/step - loss: 2.5628e-06 - accuracy: 1.0000 - val_loss: 2.9866 - val_accuracy: 0.7340\n",
      "Epoch 115/150\n",
      "11/11 [==============================] - 48s 4s/step - loss: 2.4445e-06 - accuracy: 1.0000 - val_loss: 3.0037 - val_accuracy: 0.7287\n",
      "Epoch 116/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 2.4719e-06 - accuracy: 1.0000 - val_loss: 3.0042 - val_accuracy: 0.7287\n",
      "Epoch 117/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 2.3910e-06 - accuracy: 1.0000 - val_loss: 3.0167 - val_accuracy: 0.7340\n",
      "Epoch 118/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 2.2828e-06 - accuracy: 1.0000 - val_loss: 3.0084 - val_accuracy: 0.7340\n",
      "Epoch 119/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 2.1290e-06 - accuracy: 1.0000 - val_loss: 3.0354 - val_accuracy: 0.7340\n",
      "Epoch 120/150\n",
      "11/11 [==============================] - 54s 5s/step - loss: 2.1369e-06 - accuracy: 1.0000 - val_loss: 3.0320 - val_accuracy: 0.7234\n",
      "Epoch 121/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 2.0448e-06 - accuracy: 1.0000 - val_loss: 3.0482 - val_accuracy: 0.7181\n",
      "Epoch 122/150\n",
      "11/11 [==============================] - 48s 4s/step - loss: 1.9582e-06 - accuracy: 1.0000 - val_loss: 3.0437 - val_accuracy: 0.7234\n",
      "Epoch 123/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 1.9072e-06 - accuracy: 1.0000 - val_loss: 3.0513 - val_accuracy: 0.7287\n",
      "Epoch 124/150\n",
      "11/11 [==============================] - 47s 4s/step - loss: 1.8587e-06 - accuracy: 1.0000 - val_loss: 3.0571 - val_accuracy: 0.7181\n",
      "Epoch 125/150\n",
      "11/11 [==============================] - 53s 5s/step - loss: 1.8129e-06 - accuracy: 1.0000 - val_loss: 3.0595 - val_accuracy: 0.7234\n",
      "Epoch 126/150\n",
      "11/11 [==============================] - 53s 5s/step - loss: 1.7562e-06 - accuracy: 1.0000 - val_loss: 3.0735 - val_accuracy: 0.7128\n",
      "Epoch 127/150\n",
      "11/11 [==============================] - 52s 5s/step - loss: 1.7256e-06 - accuracy: 1.0000 - val_loss: 3.0789 - val_accuracy: 0.7181\n",
      "Epoch 128/150\n",
      "11/11 [==============================] - 48s 4s/step - loss: 1.6766e-06 - accuracy: 1.0000 - val_loss: 3.0876 - val_accuracy: 0.7128\n",
      "Epoch 129/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 1.6085e-06 - accuracy: 1.0000 - val_loss: 3.1001 - val_accuracy: 0.7128\n",
      "Epoch 130/150\n",
      "11/11 [==============================] - 54s 5s/step - loss: 1.5744e-06 - accuracy: 1.0000 - val_loss: 3.0950 - val_accuracy: 0.7181\n",
      "Epoch 131/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 1.5610e-06 - accuracy: 1.0000 - val_loss: 3.1017 - val_accuracy: 0.7128\n",
      "Epoch 132/150\n",
      "11/11 [==============================] - 52s 5s/step - loss: 1.5646e-06 - accuracy: 1.0000 - val_loss: 3.1215 - val_accuracy: 0.7128\n",
      "Epoch 133/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 1.4804e-06 - accuracy: 1.0000 - val_loss: 3.1100 - val_accuracy: 0.7074\n",
      "Epoch 134/150\n",
      "11/11 [==============================] - 49s 4s/step - loss: 1.4024e-06 - accuracy: 1.0000 - val_loss: 3.1287 - val_accuracy: 0.7074\n",
      "Epoch 135/150\n",
      "11/11 [==============================] - 54s 5s/step - loss: 1.3703e-06 - accuracy: 1.0000 - val_loss: 3.1373 - val_accuracy: 0.7128\n",
      "Epoch 136/150\n",
      "11/11 [==============================] - 61s 6s/step - loss: 1.3323e-06 - accuracy: 1.0000 - val_loss: 3.1372 - val_accuracy: 0.7074\n",
      "Epoch 137/150\n",
      "11/11 [==============================] - 50s 5s/step - loss: 1.3141e-06 - accuracy: 1.0000 - val_loss: 3.1552 - val_accuracy: 0.7074\n",
      "Epoch 138/150\n",
      "11/11 [==============================] - 58s 5s/step - loss: 1.2648e-06 - accuracy: 1.0000 - val_loss: 3.1361 - val_accuracy: 0.7074\n",
      "Epoch 139/150\n",
      "11/11 [==============================] - 53s 5s/step - loss: 1.2292e-06 - accuracy: 1.0000 - val_loss: 3.1764 - val_accuracy: 0.7074\n",
      "Epoch 140/150\n",
      "11/11 [==============================] - 49s 4s/step - loss: 1.2080e-06 - accuracy: 1.0000 - val_loss: 3.1642 - val_accuracy: 0.7074\n",
      "Epoch 141/150\n",
      "11/11 [==============================] - 55s 5s/step - loss: 1.1728e-06 - accuracy: 1.0000 - val_loss: 3.1690 - val_accuracy: 0.7074\n",
      "Epoch 142/150\n",
      "11/11 [==============================] - 54s 5s/step - loss: 1.1339e-06 - accuracy: 1.0000 - val_loss: 3.1904 - val_accuracy: 0.7074\n",
      "Epoch 143/150\n",
      "11/11 [==============================] - 51s 5s/step - loss: 1.0973e-06 - accuracy: 1.0000 - val_loss: 3.1789 - val_accuracy: 0.7074\n",
      "Epoch 144/150\n",
      "11/11 [==============================] - 49s 4s/step - loss: 1.0990e-06 - accuracy: 1.0000 - val_loss: 3.1963 - val_accuracy: 0.7074\n",
      "Epoch 145/150\n",
      "11/11 [==============================] - 49s 5s/step - loss: 1.0422e-06 - accuracy: 1.0000 - val_loss: 3.2123 - val_accuracy: 0.7021\n",
      "Epoch 146/150\n",
      "11/11 [==============================] - 49s 5s/step - loss: 1.0265e-06 - accuracy: 1.0000 - val_loss: 3.2051 - val_accuracy: 0.7074\n",
      "Epoch 147/150\n",
      "11/11 [==============================] - 49s 5s/step - loss: 1.0158e-06 - accuracy: 1.0000 - val_loss: 3.2175 - val_accuracy: 0.7021\n",
      "Epoch 148/150\n",
      "11/11 [==============================] - 49s 4s/step - loss: 9.7005e-07 - accuracy: 1.0000 - val_loss: 3.2061 - val_accuracy: 0.7074\n",
      "Epoch 149/150\n",
      "11/11 [==============================] - 49s 5s/step - loss: 9.5582e-07 - accuracy: 1.0000 - val_loss: 3.2339 - val_accuracy: 0.7021\n",
      "Epoch 150/150\n",
      "11/11 [==============================] - 49s 5s/step - loss: 9.3937e-07 - accuracy: 1.0000 - val_loss: 3.2393 - val_accuracy: 0.7021\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train, y_train, epochs=150,batch_size = 40 ,validation_data= (x_Test, y_Test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras_model_conv2D_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4_input (InputLayer)  [(None, 224, 224, 3)]    0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 224, 224, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 112, 112, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 200704)            0         \n",
      "                                                                 \n",
      " feature_dense1 (Dense)      (None, 256)               51380480  \n",
      "                                                                 \n",
      " feature_dense2 (Dense)      (None, 128)               32896     \n",
      "                                                                 \n",
      " feature_dense3 (Dense)      (None, 64)                8256      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,810,048\n",
      "Trainable params: 51,810,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "model = load_model('keras_model_conv2D_v2.h5')\n",
    "\n",
    "intermediate_layer_model = Model(inputs=model.input,outputs=model.get_layer('feature_dense3').output)\n",
    "intermediate_layer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=[]\n",
    "for i in range(0,438):\n",
    "    #print(filenames[i])\n",
    "    files.append('train_generator\\\\'+str(i))\n",
    "    \n",
    "filenames=[]\n",
    "for f in files:\n",
    "    x=f.replace('\\\\',\"/\",1)\n",
    "    filenames.append('final/train/'+ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = []\n",
    "for i in range(64):\n",
    "    new_col.append('Feature_%d'%(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'final/train/train_generator/0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-47c9f8dda61a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintermediate_layer_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-47c9f8dda61a>\u001b[0m in \u001b[0;36mload\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mnp_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mnp_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnp_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2891\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2892\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'final/train/train_generator/0'"
     ]
    }
   ],
   "source": [
    "preds=[]\n",
    "def load(filename):\n",
    "    np_image = Image.open(filename)\n",
    "    np_image = np.array(np_image).astype('float32')/255\n",
    "    np_image = transform.resize(np_image, (224, 224, 3))\n",
    "    np_image = np.expand_dims(np_image, axis=0)\n",
    "    return np_image\n",
    "\n",
    "for f in filenames:\n",
    "    image = load(f)\n",
    "    files.append(f)\n",
    "    pred=intermediate_layer_model.predict(image)\n",
    "    preds.append(pred)\n",
    "\n",
    "df = pd.DataFrame (preds)\n",
    "filepath = 'new_data.xlsx'\n",
    "\n",
    "df.to_excel(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
