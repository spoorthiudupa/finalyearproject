{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline CNN and creation of BSD\n",
    "\n",
    "### This file has the results of the baseline CNN and the creation of BSD dataset. The steps performed are:\n",
    "\n",
    "1. This dataset consists of 2302 training and 998 test samples. \n",
    "2. The experimental dataset is randomly split into train and test sets with a split ratio of 70:30.\n",
    "3. The baseline CNN model has four convolutional layers with 15 filters each of size 3*3. \n",
    "4. Adam's technique is used as the optimizer. Binary cross-entropy is used as the loss function. \n",
    "5. This CNN is trained for 150 epochs. \n",
    "6. Softmax is used as the final activation function which outputs predicted probabilities. \n",
    "7. The BSD is created which contains all the samples whose confidence factor is less than a certain threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import random\n",
    "import imageio\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import backend as K\n",
    "import keras.optimizers as optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.models import load_model\n",
    "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation, BatchNormalization\n",
    "from keras.optimizers import SGD,RMSprop,Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The malignant and benign data is loaded to np arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "def Load_data_malignant():\n",
    "    path =\"Dataset_Final/malignant\"\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(1, 1500):\n",
    "        img = imageio.imread(path +'/' + str(i) + '.jpg')\n",
    "        lab = 1 \n",
    "        x_out.append(img)\n",
    "        y_out.append(lab)\n",
    "    return x_out, y_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_data_benign():\n",
    "    path =\"Dataset_Final/benign\"\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(1, 1800):\n",
    "        img = imageio.imread(path +'/' + str(i) + '.jpg')\n",
    "        lab = 0 \n",
    "        x_out.append(img)\n",
    "        y_out.append(lab)\n",
    "    return x_out, y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benign and malignant arrays are assigned to x and y arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0, y_0 = Load_data_benign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1, y_1 = Load_data_malignant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = np.array(x_0)\n",
    "y_0 = np.array(y_0)\n",
    "\n",
    "x_1 = np.array(x_1)\n",
    "y_1 = np.array(y_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arrays are concatenated to form x and y arrays (features, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "x=np.concatenate((x_0, x_1), axis=0)\n",
    "y=np.concatenate((y_0, y_1), axis=0)\n",
    "\n",
    "y = np_utils.to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is split as train and test with 70:30 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_Test, y_train, y_Test = train_test_split(x, y, test_size=0.3, random_state=5,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN model is defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nClasses = 2\n",
    "\n",
    "def createModel():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(15, (3, 3), padding='valid', activation='relu', input_shape=(224,224,3)))\n",
    "    model.add(BatchNormalization())\n",
    "      \n",
    "    model.add(Conv2D(15, (3, 3), padding='same',activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    " \n",
    "    model.add(Conv2D(15, (3, 3), padding='same',activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(15, (3, 3), padding='valid', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "    model.summary()\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer is chosen as Adam, binary cross entropy is the loss function, with epochs as 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 15)      420       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 222, 222, 15)     60        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 222, 222, 15)      2040      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 222, 222, 15)     60        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 15)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 111, 111, 15)      0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 111, 111, 15)      2040      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 111, 111, 15)     60        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 55, 55, 15)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 55, 55, 15)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 53, 53, 15)        2040      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 53, 53, 15)       60        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 15)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10140)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               1014100   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,021,082\n",
      "Trainable params: 1,020,962\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spoor\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model1 = None\n",
    "model1 = createModel()\n",
    "batch_size = 40\n",
    "epochs = 150\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.99, epsilon=None, decay=0)\n",
    "model1.compile(loss='binary_crossentropy', optimizer=opt,metrics = ['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is fit to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "58/58 [==============================] - 112s 2s/step - loss: 0.7045 - categorical_accuracy: 0.7704 - val_loss: 0.5355 - val_categorical_accuracy: 0.7313\n",
      "Epoch 2/150\n",
      "58/58 [==============================] - 108s 2s/step - loss: 0.4040 - categorical_accuracy: 0.8072 - val_loss: 0.9080 - val_categorical_accuracy: 0.7010\n",
      "Epoch 3/150\n",
      "58/58 [==============================] - 105s 2s/step - loss: 0.3727 - categorical_accuracy: 0.8224 - val_loss: 0.7965 - val_categorical_accuracy: 0.7414\n",
      "Epoch 4/150\n",
      "58/58 [==============================] - 105s 2s/step - loss: 0.3585 - categorical_accuracy: 0.8284 - val_loss: 0.7691 - val_categorical_accuracy: 0.7404\n",
      "Epoch 5/150\n",
      "58/58 [==============================] - 105s 2s/step - loss: 0.3609 - categorical_accuracy: 0.8150 - val_loss: 0.6084 - val_categorical_accuracy: 0.7808\n",
      "Epoch 6/150\n",
      "58/58 [==============================] - 105s 2s/step - loss: 0.3446 - categorical_accuracy: 0.8267 - val_loss: 0.7854 - val_categorical_accuracy: 0.7162\n",
      "Epoch 7/150\n",
      "58/58 [==============================] - 109s 2s/step - loss: 0.3049 - categorical_accuracy: 0.8488 - val_loss: 0.5524 - val_categorical_accuracy: 0.7626\n",
      "Epoch 8/150\n",
      "58/58 [==============================] - 115s 2s/step - loss: 0.3121 - categorical_accuracy: 0.8462 - val_loss: 0.4493 - val_categorical_accuracy: 0.8182\n",
      "Epoch 9/150\n",
      "58/58 [==============================] - 120s 2s/step - loss: 0.3167 - categorical_accuracy: 0.8518 - val_loss: 1.8992 - val_categorical_accuracy: 0.7192\n",
      "Epoch 10/150\n",
      "58/58 [==============================] - 116s 2s/step - loss: 0.3065 - categorical_accuracy: 0.8640 - val_loss: 1.2938 - val_categorical_accuracy: 0.7354\n",
      "Epoch 11/150\n",
      "58/58 [==============================] - 116s 2s/step - loss: 0.2755 - categorical_accuracy: 0.8653 - val_loss: 0.6385 - val_categorical_accuracy: 0.7828\n",
      "Epoch 12/150\n",
      "58/58 [==============================] - 117s 2s/step - loss: 0.2420 - categorical_accuracy: 0.8808 - val_loss: 0.8948 - val_categorical_accuracy: 0.7525\n",
      "Epoch 13/150\n",
      "58/58 [==============================] - 116s 2s/step - loss: 0.2349 - categorical_accuracy: 0.8930 - val_loss: 0.7960 - val_categorical_accuracy: 0.7566\n",
      "Epoch 14/150\n",
      "58/58 [==============================] - 117s 2s/step - loss: 0.2253 - categorical_accuracy: 0.8990 - val_loss: 0.5344 - val_categorical_accuracy: 0.8020\n",
      "Epoch 15/150\n",
      "58/58 [==============================] - 119s 2s/step - loss: 0.1995 - categorical_accuracy: 0.9055 - val_loss: 1.0809 - val_categorical_accuracy: 0.7556\n",
      "Epoch 16/150\n",
      "58/58 [==============================] - 119s 2s/step - loss: 0.1990 - categorical_accuracy: 0.9042 - val_loss: 1.0172 - val_categorical_accuracy: 0.7657\n",
      "Epoch 17/150\n",
      "58/58 [==============================] - 124s 2s/step - loss: 0.1811 - categorical_accuracy: 0.9250 - val_loss: 0.6191 - val_categorical_accuracy: 0.7636\n",
      "Epoch 18/150\n",
      "58/58 [==============================] - 118s 2s/step - loss: 0.1772 - categorical_accuracy: 0.9285 - val_loss: 0.6612 - val_categorical_accuracy: 0.8010\n",
      "Epoch 19/150\n",
      "58/58 [==============================] - 120s 2s/step - loss: 0.1701 - categorical_accuracy: 0.9272 - val_loss: 0.8565 - val_categorical_accuracy: 0.7354\n",
      "Epoch 20/150\n",
      "58/58 [==============================] - 119s 2s/step - loss: 0.1531 - categorical_accuracy: 0.9302 - val_loss: 0.6735 - val_categorical_accuracy: 0.8212\n",
      "Epoch 21/150\n",
      "58/58 [==============================] - 120s 2s/step - loss: 0.1586 - categorical_accuracy: 0.9341 - val_loss: 1.0644 - val_categorical_accuracy: 0.7535\n",
      "Epoch 22/150\n",
      "58/58 [==============================] - 120s 2s/step - loss: 0.1244 - categorical_accuracy: 0.9532 - val_loss: 0.7057 - val_categorical_accuracy: 0.8020\n",
      "Epoch 23/150\n",
      "58/58 [==============================] - 117s 2s/step - loss: 0.1170 - categorical_accuracy: 0.9510 - val_loss: 0.7198 - val_categorical_accuracy: 0.7970\n",
      "Epoch 24/150\n",
      "58/58 [==============================] - 120s 2s/step - loss: 0.1251 - categorical_accuracy: 0.9484 - val_loss: 0.7739 - val_categorical_accuracy: 0.7889\n",
      "Epoch 25/150\n",
      "58/58 [==============================] - 121s 2s/step - loss: 0.1202 - categorical_accuracy: 0.9554 - val_loss: 1.8736 - val_categorical_accuracy: 0.7232\n",
      "Epoch 26/150\n",
      "58/58 [==============================] - 117s 2s/step - loss: 0.1201 - categorical_accuracy: 0.9580 - val_loss: 2.9119 - val_categorical_accuracy: 0.7525\n",
      "Epoch 27/150\n",
      "58/58 [==============================] - 117s 2s/step - loss: 0.0872 - categorical_accuracy: 0.9658 - val_loss: 0.8725 - val_categorical_accuracy: 0.7939\n",
      "Epoch 28/150\n",
      "58/58 [==============================] - 98s 2s/step - loss: 0.0714 - categorical_accuracy: 0.9714 - val_loss: 1.4159 - val_categorical_accuracy: 0.7778\n",
      "Epoch 29/150\n",
      "58/58 [==============================] - 98s 2s/step - loss: 0.0702 - categorical_accuracy: 0.9714 - val_loss: 1.0985 - val_categorical_accuracy: 0.7646\n",
      "Epoch 30/150\n",
      "58/58 [==============================] - 98s 2s/step - loss: 0.0872 - categorical_accuracy: 0.9653 - val_loss: 1.1692 - val_categorical_accuracy: 0.7616\n",
      "Epoch 31/150\n",
      "58/58 [==============================] - 100s 2s/step - loss: 0.0963 - categorical_accuracy: 0.9679 - val_loss: 1.2408 - val_categorical_accuracy: 0.8000\n",
      "Epoch 32/150\n",
      "58/58 [==============================] - 99s 2s/step - loss: 0.0735 - categorical_accuracy: 0.9710 - val_loss: 0.8400 - val_categorical_accuracy: 0.8414\n",
      "Epoch 33/150\n",
      "58/58 [==============================] - 102s 2s/step - loss: 0.0932 - categorical_accuracy: 0.9666 - val_loss: 3.4696 - val_categorical_accuracy: 0.7222\n",
      "Epoch 34/150\n",
      "58/58 [==============================] - 97s 2s/step - loss: 0.0894 - categorical_accuracy: 0.9701 - val_loss: 1.1776 - val_categorical_accuracy: 0.7768\n",
      "Epoch 35/150\n",
      "58/58 [==============================] - 97s 2s/step - loss: 0.0733 - categorical_accuracy: 0.9723 - val_loss: 1.0946 - val_categorical_accuracy: 0.8202\n",
      "Epoch 36/150\n",
      "58/58 [==============================] - 97s 2s/step - loss: 0.0680 - categorical_accuracy: 0.9740 - val_loss: 1.7570 - val_categorical_accuracy: 0.7626\n",
      "Epoch 37/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0599 - categorical_accuracy: 0.9775 - val_loss: 0.8616 - val_categorical_accuracy: 0.8051\n",
      "Epoch 38/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0461 - categorical_accuracy: 0.9796 - val_loss: 1.3892 - val_categorical_accuracy: 0.8000\n",
      "Epoch 39/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0562 - categorical_accuracy: 0.9796 - val_loss: 0.9291 - val_categorical_accuracy: 0.8202\n",
      "Epoch 40/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0499 - categorical_accuracy: 0.9822 - val_loss: 1.0200 - val_categorical_accuracy: 0.8030\n",
      "Epoch 41/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0536 - categorical_accuracy: 0.9801 - val_loss: 0.8868 - val_categorical_accuracy: 0.8222\n",
      "Epoch 42/150\n",
      "58/58 [==============================] - 100s 2s/step - loss: 0.0641 - categorical_accuracy: 0.9788 - val_loss: 0.6309 - val_categorical_accuracy: 0.8091\n",
      "Epoch 43/150\n",
      "58/58 [==============================] - 99s 2s/step - loss: 0.0469 - categorical_accuracy: 0.9853 - val_loss: 0.9260 - val_categorical_accuracy: 0.8273\n",
      "Epoch 44/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0473 - categorical_accuracy: 0.9809 - val_loss: 0.8549 - val_categorical_accuracy: 0.8404\n",
      "Epoch 45/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0335 - categorical_accuracy: 0.9905 - val_loss: 1.0742 - val_categorical_accuracy: 0.8212\n",
      "Epoch 46/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0403 - categorical_accuracy: 0.9848 - val_loss: 1.5357 - val_categorical_accuracy: 0.8091\n",
      "Epoch 47/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0514 - categorical_accuracy: 0.9809 - val_loss: 0.9568 - val_categorical_accuracy: 0.8081\n",
      "Epoch 48/150\n",
      "58/58 [==============================] - 97s 2s/step - loss: 0.0328 - categorical_accuracy: 0.9896 - val_loss: 1.3457 - val_categorical_accuracy: 0.7848\n",
      "Epoch 49/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0345 - categorical_accuracy: 0.9874 - val_loss: 1.3396 - val_categorical_accuracy: 0.7848\n",
      "Epoch 50/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0439 - categorical_accuracy: 0.9840 - val_loss: 1.7094 - val_categorical_accuracy: 0.8121\n",
      "Epoch 51/150\n",
      "58/58 [==============================] - 100s 2s/step - loss: 0.0362 - categorical_accuracy: 0.9870 - val_loss: 2.9636 - val_categorical_accuracy: 0.7232\n",
      "Epoch 52/150\n",
      "58/58 [==============================] - 123s 2s/step - loss: 0.0334 - categorical_accuracy: 0.9883 - val_loss: 2.5403 - val_categorical_accuracy: 0.7253\n",
      "Epoch 53/150\n",
      "58/58 [==============================] - 118s 2s/step - loss: 0.0337 - categorical_accuracy: 0.9866 - val_loss: 1.1504 - val_categorical_accuracy: 0.8111\n",
      "Epoch 54/150\n",
      "58/58 [==============================] - 118s 2s/step - loss: 0.0274 - categorical_accuracy: 0.9913 - val_loss: 1.3989 - val_categorical_accuracy: 0.7939\n",
      "Epoch 55/150\n",
      "58/58 [==============================] - 117s 2s/step - loss: 0.0327 - categorical_accuracy: 0.9900 - val_loss: 2.4765 - val_categorical_accuracy: 0.7596\n",
      "Epoch 56/150\n",
      "58/58 [==============================] - 118s 2s/step - loss: 0.0388 - categorical_accuracy: 0.9857 - val_loss: 1.1137 - val_categorical_accuracy: 0.8232\n",
      "Epoch 57/150\n",
      "58/58 [==============================] - 118s 2s/step - loss: 0.0337 - categorical_accuracy: 0.9896 - val_loss: 1.1669 - val_categorical_accuracy: 0.7808\n",
      "Epoch 58/150\n",
      "58/58 [==============================] - 118s 2s/step - loss: 0.0370 - categorical_accuracy: 0.9896 - val_loss: 1.1366 - val_categorical_accuracy: 0.8263\n",
      "Epoch 59/150\n",
      "58/58 [==============================] - 122s 2s/step - loss: 0.0435 - categorical_accuracy: 0.9853 - val_loss: 3.2056 - val_categorical_accuracy: 0.7606\n",
      "Epoch 60/150\n",
      "58/58 [==============================] - 117s 2s/step - loss: 0.0291 - categorical_accuracy: 0.9900 - val_loss: 1.3637 - val_categorical_accuracy: 0.7990\n",
      "Epoch 61/150\n",
      "58/58 [==============================] - 118s 2s/step - loss: 0.0292 - categorical_accuracy: 0.9887 - val_loss: 0.9082 - val_categorical_accuracy: 0.8061\n",
      "Epoch 62/150\n",
      "58/58 [==============================] - 118s 2s/step - loss: 0.0257 - categorical_accuracy: 0.9922 - val_loss: 0.9777 - val_categorical_accuracy: 0.7980\n",
      "Epoch 63/150\n",
      "58/58 [==============================] - 117s 2s/step - loss: 0.0261 - categorical_accuracy: 0.9931 - val_loss: 1.2785 - val_categorical_accuracy: 0.8172\n",
      "Epoch 64/150\n",
      "58/58 [==============================] - 117s 2s/step - loss: 0.0279 - categorical_accuracy: 0.9905 - val_loss: 1.0854 - val_categorical_accuracy: 0.8384\n",
      "Epoch 65/150\n",
      "58/58 [==============================] - 117s 2s/step - loss: 0.0297 - categorical_accuracy: 0.9909 - val_loss: 1.7861 - val_categorical_accuracy: 0.7879\n",
      "Epoch 66/150\n",
      "58/58 [==============================] - 118s 2s/step - loss: 0.0261 - categorical_accuracy: 0.9922 - val_loss: 1.2412 - val_categorical_accuracy: 0.8253\n",
      "Epoch 67/150\n",
      "58/58 [==============================] - 123s 2s/step - loss: 0.0212 - categorical_accuracy: 0.9939 - val_loss: 1.6245 - val_categorical_accuracy: 0.8081\n",
      "Epoch 68/150\n",
      "58/58 [==============================] - 118s 2s/step - loss: 0.0220 - categorical_accuracy: 0.9931 - val_loss: 1.9757 - val_categorical_accuracy: 0.7485\n",
      "Epoch 69/150\n",
      "58/58 [==============================] - 111s 2s/step - loss: 0.0310 - categorical_accuracy: 0.9887 - val_loss: 1.3109 - val_categorical_accuracy: 0.8232\n",
      "Epoch 70/150\n",
      "58/58 [==============================] - 98s 2s/step - loss: 0.0305 - categorical_accuracy: 0.9909 - val_loss: 1.5792 - val_categorical_accuracy: 0.8141\n",
      "Epoch 71/150\n",
      "58/58 [==============================] - 99s 2s/step - loss: 0.0171 - categorical_accuracy: 0.9939 - val_loss: 1.9777 - val_categorical_accuracy: 0.7232\n",
      "Epoch 72/150\n",
      "58/58 [==============================] - 101s 2s/step - loss: 0.0307 - categorical_accuracy: 0.9913 - val_loss: 1.0308 - val_categorical_accuracy: 0.8283\n",
      "Epoch 73/150\n",
      "58/58 [==============================] - 100s 2s/step - loss: 0.0095 - categorical_accuracy: 0.9961 - val_loss: 1.5692 - val_categorical_accuracy: 0.8051\n",
      "Epoch 74/150\n",
      "58/58 [==============================] - 100s 2s/step - loss: 0.0170 - categorical_accuracy: 0.9957 - val_loss: 2.1175 - val_categorical_accuracy: 0.7818\n",
      "Epoch 75/150\n",
      "58/58 [==============================] - 107s 2s/step - loss: 0.0133 - categorical_accuracy: 0.9944 - val_loss: 2.0128 - val_categorical_accuracy: 0.7586\n",
      "Epoch 76/150\n",
      "58/58 [==============================] - 99s 2s/step - loss: 0.0395 - categorical_accuracy: 0.9883 - val_loss: 1.4300 - val_categorical_accuracy: 0.7788\n",
      "Epoch 77/150\n",
      "58/58 [==============================] - 99s 2s/step - loss: 0.0321 - categorical_accuracy: 0.9892 - val_loss: 1.0109 - val_categorical_accuracy: 0.8040\n",
      "Epoch 78/150\n",
      "58/58 [==============================] - 101s 2s/step - loss: 0.0096 - categorical_accuracy: 0.9961 - val_loss: 1.0559 - val_categorical_accuracy: 0.8222\n",
      "Epoch 79/150\n",
      "58/58 [==============================] - 102s 2s/step - loss: 0.0188 - categorical_accuracy: 0.9913 - val_loss: 3.1337 - val_categorical_accuracy: 0.7737\n",
      "Epoch 80/150\n",
      "58/58 [==============================] - 102s 2s/step - loss: 0.0141 - categorical_accuracy: 0.9935 - val_loss: 1.2788 - val_categorical_accuracy: 0.7889\n",
      "Epoch 81/150\n",
      "58/58 [==============================] - 102s 2s/step - loss: 0.0200 - categorical_accuracy: 0.9939 - val_loss: 1.9633 - val_categorical_accuracy: 0.7586\n",
      "Epoch 82/150\n",
      "58/58 [==============================] - 103s 2s/step - loss: 0.0214 - categorical_accuracy: 0.9939 - val_loss: 1.4166 - val_categorical_accuracy: 0.8212\n",
      "Epoch 83/150\n",
      "58/58 [==============================] - 106s 2s/step - loss: 0.0291 - categorical_accuracy: 0.9913 - val_loss: 1.8894 - val_categorical_accuracy: 0.7404\n",
      "Epoch 84/150\n",
      "58/58 [==============================] - 113s 2s/step - loss: 0.0228 - categorical_accuracy: 0.9913 - val_loss: 1.9986 - val_categorical_accuracy: 0.7687\n",
      "Epoch 85/150\n",
      "58/58 [==============================] - 106s 2s/step - loss: 0.0179 - categorical_accuracy: 0.9935 - val_loss: 1.0739 - val_categorical_accuracy: 0.8081\n",
      "Epoch 86/150\n",
      "58/58 [==============================] - 105s 2s/step - loss: 0.0236 - categorical_accuracy: 0.9926 - val_loss: 1.4220 - val_categorical_accuracy: 0.8303\n",
      "Epoch 87/150\n",
      "58/58 [==============================] - 107s 2s/step - loss: 0.0144 - categorical_accuracy: 0.9935 - val_loss: 1.3169 - val_categorical_accuracy: 0.8222\n",
      "Epoch 88/150\n",
      "58/58 [==============================] - 104s 2s/step - loss: 0.0209 - categorical_accuracy: 0.9944 - val_loss: 0.9817 - val_categorical_accuracy: 0.8051\n",
      "Epoch 89/150\n",
      "58/58 [==============================] - 105s 2s/step - loss: 0.0258 - categorical_accuracy: 0.9909 - val_loss: 1.4929 - val_categorical_accuracy: 0.7414\n",
      "Epoch 90/150\n",
      "58/58 [==============================] - 113s 2s/step - loss: 0.0173 - categorical_accuracy: 0.9948 - val_loss: 2.5693 - val_categorical_accuracy: 0.6000\n",
      "Epoch 91/150\n",
      "58/58 [==============================] - 116s 2s/step - loss: 0.0136 - categorical_accuracy: 0.9926 - val_loss: 1.3090 - val_categorical_accuracy: 0.8465\n",
      "Epoch 92/150\n",
      "58/58 [==============================] - 121s 2s/step - loss: 0.0164 - categorical_accuracy: 0.9944 - val_loss: 1.3775 - val_categorical_accuracy: 0.8212\n",
      "Epoch 93/150\n",
      "58/58 [==============================] - 117s 2s/step - loss: 0.0218 - categorical_accuracy: 0.9944 - val_loss: 1.8946 - val_categorical_accuracy: 0.7879\n",
      "Epoch 94/150\n",
      "58/58 [==============================] - 121s 2s/step - loss: 0.0157 - categorical_accuracy: 0.9944 - val_loss: 3.3388 - val_categorical_accuracy: 0.7838\n",
      "Epoch 95/150\n",
      "58/58 [==============================] - 98s 2s/step - loss: 0.0167 - categorical_accuracy: 0.9931 - val_loss: 1.8346 - val_categorical_accuracy: 0.8061\n",
      "Epoch 96/150\n",
      "58/58 [==============================] - 105s 2s/step - loss: 0.0556 - categorical_accuracy: 0.9827 - val_loss: 2.9888 - val_categorical_accuracy: 0.7737\n",
      "Epoch 97/150\n",
      "58/58 [==============================] - 99s 2s/step - loss: 0.0524 - categorical_accuracy: 0.9822 - val_loss: 1.2853 - val_categorical_accuracy: 0.8111\n",
      "Epoch 98/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.0392 - categorical_accuracy: 0.9874 - val_loss: 1.7875 - val_categorical_accuracy: 0.8253\n",
      "Epoch 99/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 95s 2s/step - loss: 0.0436 - categorical_accuracy: 0.9900 - val_loss: 4.7591 - val_categorical_accuracy: 0.7111\n",
      "Epoch 100/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.0204 - categorical_accuracy: 0.9931 - val_loss: 1.5635 - val_categorical_accuracy: 0.8071\n",
      "Epoch 101/150\n",
      "58/58 [==============================] - 99s 2s/step - loss: 0.0183 - categorical_accuracy: 0.9957 - val_loss: 1.0247 - val_categorical_accuracy: 0.8293\n",
      "Epoch 102/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.0282 - categorical_accuracy: 0.9922 - val_loss: 1.4206 - val_categorical_accuracy: 0.8172\n",
      "Epoch 103/150\n",
      "58/58 [==============================] - 98s 2s/step - loss: 0.0187 - categorical_accuracy: 0.9926 - val_loss: 3.0971 - val_categorical_accuracy: 0.7667\n",
      "Epoch 104/150\n",
      "58/58 [==============================] - 100s 2s/step - loss: 0.0176 - categorical_accuracy: 0.9961 - val_loss: 1.6808 - val_categorical_accuracy: 0.7677\n",
      "Epoch 105/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0167 - categorical_accuracy: 0.9952 - val_loss: 1.5418 - val_categorical_accuracy: 0.8040\n",
      "Epoch 106/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0255 - categorical_accuracy: 0.9944 - val_loss: 2.1560 - val_categorical_accuracy: 0.7192\n",
      "Epoch 107/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0110 - categorical_accuracy: 0.9952 - val_loss: 2.1204 - val_categorical_accuracy: 0.7818\n",
      "Epoch 108/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0208 - categorical_accuracy: 0.9935 - val_loss: 2.3296 - val_categorical_accuracy: 0.7545\n",
      "Epoch 109/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0201 - categorical_accuracy: 0.9939 - val_loss: 2.5078 - val_categorical_accuracy: 0.7182\n",
      "Epoch 110/150\n",
      "58/58 [==============================] - 100s 2s/step - loss: 0.0204 - categorical_accuracy: 0.9939 - val_loss: 1.9907 - val_categorical_accuracy: 0.7717\n",
      "Epoch 111/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0310 - categorical_accuracy: 0.9918 - val_loss: 3.5988 - val_categorical_accuracy: 0.7465\n",
      "Epoch 112/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0131 - categorical_accuracy: 0.9948 - val_loss: 3.2339 - val_categorical_accuracy: 0.7424\n",
      "Epoch 113/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0203 - categorical_accuracy: 0.9952 - val_loss: 2.2596 - val_categorical_accuracy: 0.7768\n",
      "Epoch 114/150\n",
      "58/58 [==============================] - 97s 2s/step - loss: 0.0396 - categorical_accuracy: 0.9935 - val_loss: 1.1981 - val_categorical_accuracy: 0.8051\n",
      "Epoch 115/150\n",
      "58/58 [==============================] - 97s 2s/step - loss: 0.0129 - categorical_accuracy: 0.9944 - val_loss: 1.0431 - val_categorical_accuracy: 0.8283\n",
      "Epoch 116/150\n",
      "58/58 [==============================] - 97s 2s/step - loss: 0.0081 - categorical_accuracy: 0.9974 - val_loss: 8.4738 - val_categorical_accuracy: 0.6556\n",
      "Epoch 117/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.0300 - categorical_accuracy: 0.9926 - val_loss: 1.6925 - val_categorical_accuracy: 0.7444\n",
      "Epoch 118/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.0109 - categorical_accuracy: 0.9961 - val_loss: 1.9928 - val_categorical_accuracy: 0.8020\n",
      "Epoch 119/150\n",
      "58/58 [==============================] - 97s 2s/step - loss: 0.0141 - categorical_accuracy: 0.9952 - val_loss: 1.6546 - val_categorical_accuracy: 0.7980\n",
      "Epoch 120/150\n",
      "58/58 [==============================] - 99s 2s/step - loss: 0.0178 - categorical_accuracy: 0.9935 - val_loss: 1.1576 - val_categorical_accuracy: 0.8232\n",
      "Epoch 121/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0115 - categorical_accuracy: 0.9965 - val_loss: 1.2466 - val_categorical_accuracy: 0.8273\n",
      "Epoch 122/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0124 - categorical_accuracy: 0.9961 - val_loss: 1.7810 - val_categorical_accuracy: 0.7960\n",
      "Epoch 123/150\n",
      "58/58 [==============================] - 96s 2s/step - loss: 0.0173 - categorical_accuracy: 0.9965 - val_loss: 1.3314 - val_categorical_accuracy: 0.8182\n",
      "Epoch 124/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.0184 - categorical_accuracy: 0.9939 - val_loss: 1.5265 - val_categorical_accuracy: 0.8051\n",
      "Epoch 125/150\n",
      "58/58 [==============================] - 95s 2s/step - loss: 0.0175 - categorical_accuracy: 0.9939 - val_loss: 7.5353 - val_categorical_accuracy: 0.7172\n",
      "Epoch 126/150\n",
      "58/58 [==============================] - 98s 2s/step - loss: 0.0075 - categorical_accuracy: 0.9965 - val_loss: 2.0139 - val_categorical_accuracy: 0.7990\n",
      "Epoch 127/150\n",
      "58/58 [==============================] - 111s 2s/step - loss: 0.0289 - categorical_accuracy: 0.9926 - val_loss: 1.8788 - val_categorical_accuracy: 0.8364\n",
      "Epoch 128/150\n",
      "58/58 [==============================] - 123s 2s/step - loss: 0.0303 - categorical_accuracy: 0.9926 - val_loss: 1.5726 - val_categorical_accuracy: 0.7566\n",
      "Epoch 129/150\n",
      "58/58 [==============================] - 120s 2s/step - loss: 0.0165 - categorical_accuracy: 0.9952 - val_loss: 1.3710 - val_categorical_accuracy: 0.8455\n",
      "Epoch 130/150\n",
      "58/58 [==============================] - 118s 2s/step - loss: 0.0070 - categorical_accuracy: 0.9978 - val_loss: 1.7130 - val_categorical_accuracy: 0.8263\n",
      "Epoch 131/150\n",
      "58/58 [==============================] - 119s 2s/step - loss: 0.0122 - categorical_accuracy: 0.9957 - val_loss: 2.1128 - val_categorical_accuracy: 0.8081\n",
      "Epoch 132/150\n",
      "58/58 [==============================] - 116s 2s/step - loss: 0.0111 - categorical_accuracy: 0.9957 - val_loss: 1.3232 - val_categorical_accuracy: 0.8131\n",
      "Epoch 133/150\n",
      "58/58 [==============================] - 118s 2s/step - loss: 0.0044 - categorical_accuracy: 0.9991 - val_loss: 4.6984 - val_categorical_accuracy: 0.7505\n",
      "Epoch 134/150\n",
      "58/58 [==============================] - 126s 2s/step - loss: 0.0177 - categorical_accuracy: 0.9922 - val_loss: 1.4353 - val_categorical_accuracy: 0.7667\n",
      "Epoch 135/150\n",
      "58/58 [==============================] - 121s 2s/step - loss: 0.0153 - categorical_accuracy: 0.9952 - val_loss: 1.5001 - val_categorical_accuracy: 0.8303\n",
      "Epoch 136/150\n",
      "58/58 [==============================] - 127s 2s/step - loss: 0.0236 - categorical_accuracy: 0.9931 - val_loss: 1.7750 - val_categorical_accuracy: 0.7525\n",
      "Epoch 137/150\n",
      "58/58 [==============================] - 121s 2s/step - loss: 0.0089 - categorical_accuracy: 0.9961 - val_loss: 1.6740 - val_categorical_accuracy: 0.8101\n",
      "Epoch 138/150\n",
      "58/58 [==============================] - 120s 2s/step - loss: 0.0194 - categorical_accuracy: 0.9957 - val_loss: 1.2651 - val_categorical_accuracy: 0.8323\n",
      "Epoch 139/150\n",
      "58/58 [==============================] - 119s 2s/step - loss: 0.0048 - categorical_accuracy: 0.9983 - val_loss: 2.5536 - val_categorical_accuracy: 0.8040\n",
      "Epoch 140/150\n",
      "58/58 [==============================] - 121s 2s/step - loss: 0.0068 - categorical_accuracy: 0.9970 - val_loss: 1.2542 - val_categorical_accuracy: 0.8040\n",
      "Epoch 141/150\n",
      "58/58 [==============================] - 121s 2s/step - loss: 0.0057 - categorical_accuracy: 0.9978 - val_loss: 1.4489 - val_categorical_accuracy: 0.8172\n",
      "Epoch 142/150\n",
      "58/58 [==============================] - 118s 2s/step - loss: 0.0095 - categorical_accuracy: 0.9987 - val_loss: 1.3401 - val_categorical_accuracy: 0.8354\n",
      "Epoch 143/150\n",
      "58/58 [==============================] - 127s 2s/step - loss: 0.0036 - categorical_accuracy: 0.9987 - val_loss: 1.5642 - val_categorical_accuracy: 0.8303\n",
      "Epoch 144/150\n",
      "58/58 [==============================] - 124s 2s/step - loss: 0.0072 - categorical_accuracy: 0.9978 - val_loss: 2.4613 - val_categorical_accuracy: 0.8192\n",
      "Epoch 145/150\n",
      "58/58 [==============================] - 103s 2s/step - loss: 0.0183 - categorical_accuracy: 0.9952 - val_loss: 5.5908 - val_categorical_accuracy: 0.7414\n",
      "Epoch 146/150\n",
      "58/58 [==============================] - 100s 2s/step - loss: 0.0121 - categorical_accuracy: 0.9965 - val_loss: 1.5523 - val_categorical_accuracy: 0.8091\n",
      "Epoch 147/150\n",
      "58/58 [==============================] - 101s 2s/step - loss: 0.0108 - categorical_accuracy: 0.9965 - val_loss: 1.4821 - val_categorical_accuracy: 0.8283\n",
      "Epoch 148/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 104s 2s/step - loss: 0.0062 - categorical_accuracy: 0.9974 - val_loss: 2.3110 - val_categorical_accuracy: 0.8374\n",
      "Epoch 149/150\n",
      "58/58 [==============================] - 100s 2s/step - loss: 0.0131 - categorical_accuracy: 0.9965 - val_loss: 8.3449 - val_categorical_accuracy: 0.7253\n",
      "Epoch 150/150\n",
      "58/58 [==============================] - 102s 2s/step - loss: 0.0187 - categorical_accuracy: 0.9944 - val_loss: 1.4980 - val_categorical_accuracy: 0.8020\n"
     ]
    }
   ],
   "source": [
    "history=model1.fit(x_train, y_train, epochs=150,batch_size = batch_size,validation_data= (x_Test, y_Test), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy and loss graphs are obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report of the test data is printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 6s 191ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.83       540\n",
      "           1       0.82      0.73      0.77       450\n",
      "\n",
      "    accuracy                           0.80       990\n",
      "   macro avg       0.80      0.80      0.80       990\n",
      "weighted avg       0.80      0.80      0.80       990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "pred = model1.predict(x_Test, batch_size=32, verbose=1)\n",
    "predicted = np.argmax(pred, axis=1)\n",
    "report = classification_report(np.argmax(y_Test, axis=1), predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After observing the CPVS of the test samples and the respective outputs, the threshold is calculated as 99.99995 and the BSD is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os \n",
    "for i in range(989):\n",
    "    if abs((pred[i][0]*100) - (pred[i][1]*100)) < 99.99995 :\n",
    "        img = Image.fromarray(x_Test[i], 'RGB')\n",
    "        if np.argmax(y_Test[i])== 0:\n",
    "                img.save(os.path.join('final/benign/',str(i)+'.jpg'))\n",
    "        if np.argmax(y_Test[i])== 1:\n",
    "                img.save(os.path.join('final/malignant/', str(i)+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import shutil\n",
    "\n",
    "# # Set paths to the folders containing the images\n",
    "# malignant_folder = \"C:/Users/spoor/finalproject/melanoma-detection/final/malignant\"\n",
    "# benign_folder = \"C:/Users/spoor/finalproject/melanoma-detection/final/benign\"\n",
    "\n",
    "# # Set the paths for the train and test folders\n",
    "# train_folder = \"C:/Users/spoor/finalproject/melanoma-detection/final/train\"\n",
    "# test_folder = \"C:/Users/spoor/finalproject/melanoma-detection/final/test\"\n",
    "\n",
    "# # Set the percentage of images to be used for testing\n",
    "# test_size = 0.3\n",
    "\n",
    "# # Get the list of filenames in each folder\n",
    "# malignant_files = os.listdir(malignant_folder)\n",
    "# benign_files = os.listdir(benign_folder)\n",
    "\n",
    "# # Split the filenames into train and test sets\n",
    "# malignant_train, malignant_test = train_test_split(malignant_files, test_size=test_size)\n",
    "# benign_train, benign_test = train_test_split(benign_files, test_size=test_size)\n",
    "\n",
    "# # Create the train and test folders and subfolders\n",
    "# os.makedirs(train_folder + '/malignant', exist_ok=True)\n",
    "# os.makedirs(train_folder + '/benign', exist_ok=True)\n",
    "# os.makedirs(test_folder + '/malignant', exist_ok=True)\n",
    "# os.makedirs(test_folder + '/benign', exist_ok=True)\n",
    "\n",
    "# # Copy the train and test images to the respective folders\n",
    "# for filename in malignant_train:\n",
    "#     shutil.copy(malignant_folder + '/' + filename, train_folder + '/malignant')\n",
    "# for filename in malignant_test:\n",
    "#     shutil.copy(malignant_folder + '/' + filename, test_folder + '/malignant')\n",
    "# for filename in benign_train:\n",
    "#     shutil.copy(benign_folder + '/' + filename, train_folder + '/benign')\n",
    "# for filename in benign_test:\n",
    "#     shutil.copy(benign_folder + '/' + filename, test_folder + '/benign')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set paths to the folders containing the images\n",
    "benign_folder = 'C:/Users/spoor/finalproject/melanoma-detection/final/benign'\n",
    "malignant_folder = 'C:/Users/spoor/finalproject/melanoma-detection/final/malignant'\n",
    "test_folder = 'C:/Users/spoor/finalproject/melanoma-detection/final/test'\n",
    "\n",
    "# Get the list of filenames in the benign and malignant folders\n",
    "benign_files = os.listdir(benign_folder)\n",
    "malignant_files = os.listdir(malignant_folder)\n",
    "\n",
    "# Split the filenames into training and test sets using scikit-learn\n",
    "benign_train, benign_test = train_test_split(benign_files, test_size=0.3)\n",
    "malignant_train, malignant_test = train_test_split(malignant_files, test_size=0.3)\n",
    "\n",
    "\n",
    "# Move the test images to the test folder\n",
    "for filename in benign_test:\n",
    "    source_path = benign_folder + '/' + filename\n",
    "    dest_path = test_folder + '/' + filename\n",
    "    if os.path.exists(dest_path):\n",
    "        # If file already exists in the destination folder, add a suffix to the filename\n",
    "        root, ext = os.path.splitext(filename)\n",
    "        new_filename = root + '_copy' + ext\n",
    "        dest_path = test_folder + '/' + new_filename\n",
    "    shutil.move(source_path, dest_path)\n",
    "    \n",
    "for filename in malignant_test:\n",
    "    source_path = malignant_folder + '/' + filename\n",
    "    dest_path = test_folder + '/' + filename\n",
    "    if os.path.exists(dest_path):\n",
    "        # If file already exists in the destination folder, add a suffix to the filename\n",
    "        root, ext = os.path.splitext(filename)\n",
    "        new_filename = root + '_copy' + ext\n",
    "        dest_path = test_folder + '/' + new_filename\n",
    "    shutil.move(source_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the trained CNN model\n",
    "model = load_model('keras_model_conv2D_v2.h5')\n",
    "\n",
    "# Set paths to the folders containing the images\n",
    "test_folder = 'C:/Users/spoor/finalproject/melanoma-detection/final/test'\n",
    "\n",
    "# Get the list of filenames in the test folder\n",
    "test_files = os.listdir(test_folder)\n",
    "\n",
    "# Define a function to extract features from an image using the trained model\n",
    "def extract_features(filename):\n",
    "    img = image.load_img(test_folder + '/' + filename, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #x = preprocess_input(x)\n",
    "    features = model.predict(x)\n",
    "    return features.flatten()\n",
    "\n",
    "# Extract features from each image in the test folder\n",
    "features_list = []\n",
    "for filename in test_files:\n",
    "    features = extract_features(filename)\n",
    "    features_list.append(features)\n",
    "\n",
    "# Convert the feature list to a Pandas DataFrame and save to an Excel file\n",
    "df = pd.DataFrame(features_list)\n",
    "df.to_excel('cnn.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
